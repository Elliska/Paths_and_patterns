{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ce65491",
   "metadata": {},
   "source": [
    "# Weekly Training Progress Report\n",
    "\n",
    "- Compares actual vs planned weekly distance, longest route, and training time.\n",
    "- Calculates percentage of plan completed.\n",
    "- Identifies trends (above/below plan) for distance.\n",
    "\n",
    "- uses data from a database which log the actual training and compares it to the excel training plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034a6c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from data.paths import DB_PATH, EXCEL_PATH\n",
    "\n",
    "conn = duckdb.connect(DB_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "326f6c08",
   "metadata": {},
   "source": [
    "### Database part\n",
    "\n",
    "Fetch data from a database and calculate summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1bd8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly_summary = conn.execute(\"\"\"\n",
    "    WITH weekly AS (\n",
    "        SELECT\n",
    "            strftime(activity_date, '%Y') AS year_id,\n",
    "            strftime(activity_date, '%V') AS week_id,\n",
    "            ROUND(SUM(EXTRACT(EPOCH FROM moving_time)) / 3600.0, 2) AS total_time_hours,\n",
    "            DATE_TRUNC('second', AVG(avg_pace)) AS average_pace,\n",
    "            SUM(distance_km) AS total_distance_km,\n",
    "            MAX(distance_km) AS longest_hike,\n",
    "            SUM(calories_kcal) AS total_calories,\n",
    "            SUM(steps) AS total_steps,\n",
    "            SUM(total_ascent) AS total_ascend_meters,\n",
    "            SUM(total_descent) AS total_descent_meters,\n",
    "            ROUND(AVG(min_temp_c),2) AS average_temperature,\n",
    "            MIN(activity_date) AS week_start\n",
    "        FROM tbl_activity\n",
    "        WHERE EXTRACT(YEAR FROM activity_date) = EXTRACT(YEAR FROM CURRENT_DATE)\n",
    "        GROUP BY year_id, week_id\n",
    "        ORDER BY year_id, week_id DESC \n",
    "    )\n",
    "    SELECT * FROM weekly;\n",
    "             \"\"\").fetchdf()  # ← fetch as Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba25c9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly_comparison = conn.execute(\"\"\"\n",
    "    WITH weekly AS (\n",
    "        SELECT\n",
    "            strftime(activity_date, '%Y')   AS year_id,\n",
    "            strftime(activity_date, '%V')   AS week_id,\n",
    "            MIN(activity_date)              AS week_start,\n",
    "            ROUND(SUM(EXTRACT(EPOCH FROM moving_time)) / 3600.0, 2) AS total_time_hours,\n",
    "            MAX(distance_km)\t\t\t \tAS longest_hike, \n",
    "            -- convert pace to seconds for math\n",
    "            AVG(EXTRACT(EPOCH FROM CAST(avg_pace AS INTERVAL))) AS average_pace_sec,\n",
    "            SUM(distance_km)                AS total_distance_km,\n",
    "        FROM tbl_activity\n",
    "        WHERE EXTRACT(YEAR FROM activity_date) = EXTRACT(YEAR FROM CURRENT_DATE)\n",
    "        GROUP BY year_id, week_id\n",
    "    )\n",
    "    SELECT\n",
    "        --year_id,\n",
    "        week_id,\n",
    "        ROUND(\n",
    "        100.0 * ( longest_hike - LAG(longest_hike) OVER (ORDER BY week_start asc) )\n",
    "                / NULLIF(LAG(longest_hike) OVER (ORDER BY week_start asc), 0),\n",
    "        1\n",
    "        ) AS pct_change_longest,\n",
    "        ROUND(\n",
    "        100.0 * ( total_distance_km - LAG(total_distance_km) OVER (ORDER BY week_start asc) )\n",
    "                / NULLIF(LAG(total_distance_km) OVER (ORDER BY week_start asc), 0),\n",
    "        1\n",
    "        ) AS pct_change_total_distance,\n",
    "        ROUND(\n",
    "        100.0 * ( total_time_hours - LAG(total_time_hours) OVER (ORDER BY week_start asc) )\n",
    "                / NULLIF(LAG(total_time_hours) OVER (ORDER BY week_start asc), 0),\n",
    "        1\n",
    "        ) AS pct_change_hiked_time,\n",
    "        ROUND(\n",
    "        100.0 * ( LAG(average_pace_sec) OVER (ORDER BY week_start asc) - average_pace_sec )\n",
    "                / NULLIF(LAG(average_pace_sec) OVER (ORDER BY week_start asc), 0),\n",
    "        1\n",
    "        ) AS pct_change_pace,\n",
    "        longest_hike,\n",
    "        LAG(longest_hike) OVER (ORDER BY week_start ASC) AS prev_longest_hike,\n",
    "        total_distance_km,\n",
    "        LAG(total_distance_km) OVER (ORDER BY week_start asc) AS prev_distance_km,\n",
    "        total_time_hours,\n",
    "        LAG(total_time_hours) OVER (ORDER BY week_start asc) AS prev_time_hours,\n",
    "        -- INTERVAL display for readability\n",
    "        INTERVAL '1 second' * ROUND(average_pace_sec) AS average_pace,\n",
    "        INTERVAL '1 second' * ROUND(LAG(average_pace_sec) OVER (ORDER BY week_start asc)) AS prev_average_pace\n",
    "    FROM weekly\n",
    "    ORDER BY week_start DESC;\n",
    "\"\"\").fetchdf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6812eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly_best_time = conn.execute(\"\"\"\n",
    "    WITH weekly_fastest AS (\n",
    "        SELECT\n",
    "            strftime(activity_date, '%Y') AS year_id,\n",
    "            strftime(activity_date, '%V') AS week_id,\n",
    "            activity_date,\n",
    "            distance_km,\n",
    "            ROUND(1/(EXTRACT(EPOCH FROM CAST(avg_pace AS INTERVAL))/3600),2) AS avg_speed, \n",
    "            EXTRACT(EPOCH FROM CAST(avg_pace AS INTERVAL)) AS pace_sec, \n",
    "            avg_pace,\n",
    "            avg_cadence,\n",
    "            avg_stride_lenght,\n",
    "            elapsed_time - moving_time AS inactive_time,\n",
    "            total_ascent,\n",
    "            total_descent\n",
    "        FROM tbl_activity\n",
    "        WHERE EXTRACT(YEAR FROM activity_date) = EXTRACT(YEAR FROM CURRENT_DATE)\n",
    "    )\n",
    "    SELECT\n",
    "        week_id,\n",
    "        distance_km,\n",
    "        ROUND(distance_km / LAG(distance_km) OVER (ORDER BY year_id, week_id) * 100, 2) AS prc_prev_week_km,\n",
    "        ROUND((avg_speed - LAG(avg_speed) OVER (ORDER BY year_id, week_id)) \n",
    "        / LAG(avg_speed) OVER (ORDER BY year_id, week_id) * 100, 2) AS speed_change_pct,\n",
    "        avg_speed,\n",
    "        -- Distances for prev week\n",
    "        --LAG(distance_km) OVER (ORDER BY year_id, week_id) AS prev_week_km,\n",
    "        -- Avg speed for prev week\n",
    "        LAG(avg_speed) OVER (ORDER BY year_id, week_id) AS prev_week_speed,\n",
    "        avg_pace,\n",
    "        LAG(avg_pace) OVER (ORDER BY year_id, week_id ASC )AS prev_week_pace,\n",
    "        avg_cadence,\n",
    "        avg_stride_lenght,\n",
    "        inactive_time,\n",
    "        total_ascent,\n",
    "        total_descent\n",
    "    FROM weekly_fastest w1\n",
    "    WHERE pace_sec = (\n",
    "        SELECT MIN(pace_sec)\n",
    "        FROM weekly_fastest w2\n",
    "        WHERE w2.week_id = w1.week_id\n",
    "    )\n",
    "    ORDER BY year_id DESC, week_id DESC;\n",
    "\"\"\").fetch_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c2d435",
   "metadata": {},
   "source": [
    "### Excel part\n",
    "\n",
    "Compare reality with a plan from excel.\n",
    "\n",
    "But first connect excel and prepare columns into a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e35a1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the plan\n",
    "plan_df = pd.read_excel(EXCEL_PATH, sheet_name=\"plán\", parse_dates=[\"pondělí\"], engine=\"openpyxl\", usecols=\"A:H\") \n",
    "\n",
    "for col in [\"nejdelší trasa\", \"celkem týden\", \"doba v minutách\", \"doba v hodinách\"]:\n",
    "    plan_df[col] = plan_df[col].astype(str).str.replace(\",\", \".\").astype(float)\n",
    "\n",
    "plan_df['year_id_plan'] = plan_df['pondělí'].dt.year\n",
    "plan_df = plan_df.dropna(subset=['year_id_plan'])\n",
    "\n",
    "# Rename columns for convenience\n",
    "plan_df = plan_df.rename(columns={\n",
    "    \"pondělí\": \"date\",\n",
    "    \"týden roku\": \"week_id_plan\",\n",
    "    \"tréninkový týden\": \"training_week\",\n",
    "    \"nejdelší trasa\": \"longest_route_km_plan\",\n",
    "    \"celkem týden\": \"total_distance_km_plan\",\n",
    "    \"zbývá denně ujít\": \"remaining_daily_km\",\n",
    "    \"doba v minutách\": \"time_min_plan\",\n",
    "    \"doba v hodinách\": \"time_hours_plan\"\n",
    "})\n",
    "\n",
    "# only to have a future plan shown (split into two so I can also compare past plans)\n",
    "current_year = datetime.now().year\n",
    "current_week = datetime.now().isocalendar().week\n",
    "\n",
    "plan_future_df = plan_df[\n",
    "    (plan_df['year_id_plan'] == current_year) &\n",
    "    (plan_df['week_id_plan'] >= current_week)\n",
    "].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee04733e",
   "metadata": {},
   "source": [
    "Ensure datatypes are correct and same for calculations - issues on year_id_plan = float + NaN (NaN dropped earlier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564a6867",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure year_id is int in both DataFrames\n",
    "plan_df['year_id_plan'] = plan_df['year_id_plan'].astype(int)\n",
    "weekly_summary['year_id'] = weekly_summary['year_id'].astype(int)\n",
    "\n",
    "# Also ensure week_id is int\n",
    "plan_df['week_id_plan'] = plan_df['week_id_plan'].astype(int)\n",
    "weekly_summary['week_id'] = weekly_summary['week_id'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e7214ba",
   "metadata": {},
   "source": [
    "Merge dataframes together to one for comparison and make some basic calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbbb73d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_df = pd.merge(\n",
    "    weekly_summary,\n",
    "    plan_df,\n",
    "    left_on=['year_id', 'week_id'],\n",
    "    right_on=['year_id_plan', 'week_id_plan'],  # your Excel column\n",
    "    suffixes=('_actual', '_plan')\n",
    ")\n",
    "\n",
    "comparison_df = comparison_df[[\n",
    "    \"week_id\",\"week_start\",\n",
    "    \"total_distance_km\", \"total_distance_km_plan\", \n",
    "    \"longest_hike\", \"longest_route_km_plan\",\n",
    "    \"total_time_hours\", \"time_hours_plan\"\n",
    "]]\n",
    "\n",
    "# % of planned total distance\n",
    "comparison_df['pct_distance'] = 100 * comparison_df['total_distance_km'] / comparison_df['total_distance_km_plan']\n",
    "\n",
    "# % of planned longest hike\n",
    "comparison_df['pct_longest_hike'] = 100 * comparison_df['longest_hike'] / comparison_df['longest_route_km_plan']\n",
    "\n",
    "# % of planned time\n",
    "comparison_df['pct_time'] = 100 * comparison_df['total_time_hours'] / comparison_df['time_hours_plan']\n",
    "\n",
    "# trend based on distance\n",
    "comparison_df['distance_trend'] = comparison_df['pct_distance'].apply(lambda x: 'above plan' if x >= 100 else 'below plan')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e158a0f1",
   "metadata": {},
   "source": [
    "# Summaries and analyses\n",
    "\n",
    "### Weekly summary\n",
    "* shows only a summary of the week's progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211e4d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly_summary.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c78cc747",
   "metadata": {},
   "source": [
    "### Weekly summary comparison\n",
    "* compares the actual past training between weeks to show trends and improvements or space for improvements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d311bd33",
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly_comparison.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab45faa",
   "metadata": {},
   "source": [
    "### Weekly fastest activity\n",
    "\n",
    "* shows fastest activity per week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd03993",
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly_best_time.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a36fd1",
   "metadata": {},
   "source": [
    "### Weekly plan\n",
    "* what has been planned in training plan in excel for past and following weeks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a385c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plan_future_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60987e4f",
   "metadata": {},
   "source": [
    "### Plan vs. reality\n",
    "* comparison of a plan vs reality to see if I am adhering to the plan an/or by how much."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ce0098",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show only key columns in a readable table\n",
    "display(comparison_df[['week_id','week_start', 'total_distance_km', 'total_distance_km_plan',\n",
    "                       'pct_distance', 'longest_hike', 'longest_route_km_plan',\n",
    "                       'pct_longest_hike', 'total_time_hours', 'time_hours_plan', 'pct_time',\n",
    "                       'distance_trend']].round(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b56b60",
   "metadata": {},
   "source": [
    "### Weekly distance\n",
    "* a graph to show if I am adhering to a planned kilometers or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888b3016",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    plt.figure(figsize=(12,6), facecolor=\"#252526\")  # figure background\n",
    "\n",
    "    weeks = comparison_df['week_id']\n",
    "\n",
    "    plt.plot(weeks, comparison_df['total_distance_km_plan'],\n",
    "            label='Planned',\n",
    "            marker='o',\n",
    "            markersize=8,\n",
    "            markerfacecolor='white',\n",
    "            markeredgecolor='blue',\n",
    "            color='blue',\n",
    "            linestyle='-',  # solid line\n",
    "            linewidth=2)\n",
    "\n",
    "    plt.plot(weeks, comparison_df['total_distance_km'],\n",
    "            label='Actual',\n",
    "            marker='s',\n",
    "            markersize=8,\n",
    "            markerfacecolor='orange',\n",
    "            markeredgecolor='darkorange',\n",
    "            color='orange',\n",
    "            linestyle='--',  # dashed line\n",
    "            linewidth=2)\n",
    "\n",
    "    plt.xlabel('Week', fontsize=12, color='white')\n",
    "    plt.ylabel('Distance (km)', fontsize=12, color='white')\n",
    "    plt.title('Weekly Distance: Actual vs Planned', fontsize=14, weight='bold', color='white')\n",
    "    plt.xticks(color='white')\n",
    "    plt.yticks(color='white')\n",
    "    plt.legend(facecolor='#555555', edgecolor='white', labelcolor='white')\n",
    "    plt.grid(True, linestyle='--', alpha=0.5, color='white')\n",
    "\n",
    "    # axes background color\n",
    "    plt.gca().set_facecolor('#252526')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "except Exception as e:\n",
    "    print(f\"Graph not possible to render due {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.4)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
